# 海量场景下的分布式限流

本质是根据针对不同的场景在一致性和可用性之间的权衡艺术。

## 限流场景
- 服务,按服务去限流(配额高)
- 接口,对服务特定接口进行限流(配额高)
- 维度,根据请求中特定参数/标签限流(配额低)
总结:
配额高不能超限，配额低不能误限

## 业界限流方案

| 场景 | redis | nginx | Sentinel | doorman | AHAS |
|----|-------|-------|----------|---------|----------|
| 服务 | 支持    | 不支持   | 支持       | 支持      | 支持       |
| 接口 | 支持    | 支持    | 支持       | 不支持     | 支持       |
| 维度 | 支持    | 不支持   | 支持       | 不支持     | 支持       |


## 限流模式
### 单次分配 强一致
- 精准限流，会增加业务延迟
- 基于redis,sentinel实现
- 秒杀等对精准性要求较高的细粒度限流

### 批次分配  最终一致, 性能高，但准确性会降低
一般都是客户端(LRU窗口)限流 + 客户端定期上报(ms级)配额到限流器 + 限流器响应客户端剩余配额，客户端重新计算限流额
- 预分配后消费; Youtube doorman; 本地限流，会有误限的风险;单机流量在一定周期相对稳定的场景，如服务级限流，读写分离的接口级限流
- 先消费后结算; 阿里AHAS; 客户端基于剩余整体配额进行扣除，不再进行均摊，能解决误限的问题，可能会有超限; 服务\接口限流等允许一定误差的限流场景

批次分配优化：
- 精度提升: 批次分配的精度主要和上报周期相关(30-50ms, 可根据消耗速率动态调整)
- 内存优化: 本地LRU淘汰过期的限流窗口
- 热点优化: 一致性hash到对应的限流机器，退化成单机限流
- 批量上报: 每个窗口都单独上报, 性能有损,对hash到同一节点的窗口合并批量上报


## 模式选择
### 流量均匀
- 采用预分配后消费，提前给节点分配配额即可
### 流量不均
- 单机均摊配额大于等于1, 先消费后结算，批次分配，会有超限，但可控
- 单机均摊配额小于1, 单次分配


## 限流策略
- 多级限流(网关层、应用层、服务层、数据层)
- 动态阈值调整(负载高降低权重)
- 多级维度(ip,设备) + 业务侧规则(发评限制)
